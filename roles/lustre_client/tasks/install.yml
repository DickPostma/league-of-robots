---
- name: Install packages for build environment to support Dynamic Kernel Module Support (DKMS).
  ansible.builtin.package:
    state: latest
    update_cache: true
    name:
      - asciidoc
      - audit-libs-devel
      - automake
      - bc
      - binutils-devel
      - bison
      - device-mapper-devel
      - elfutils-devel
      - elfutils-libelf-devel
      - expect
      - flex
      - gcc
      - gcc-c++
      - git
      - glib2
      - glib2-devel
      - hmaccalc
      - keyutils-libs-devel
      - krb5-devel
      - ksh
      - libattr-devel
      - libblkid-devel
      - libselinux-devel
      - libtool
      - libuuid-devel
      - libyaml-devel
      - lsscsi
      - make
      - ncurses-devel
      - net-snmp-devel
      - net-tools
      - newt-devel
      - numactl-devel
      - parted
      - patchutils
      - pciutils-devel
      - perl-ExtUtils-Embed
      - pesign
      - python-devel
      - redhat-rpm-config
      - rpm-build
      - systemd-devel
      - tcl
      - tcl-devel
      - tk
      - tk-devel
      - wget
      - xmlto
      - yum-utils
      - zlib-devel
  become: true

- name: Install kernel tools/extras required for compiling kernel modules.
  ansible.builtin.package:
    state: latest
    update_cache: true
    name:
      - kernel
      - kernel-devel
      - kernel-headers
      - kernel-tools
      - kernel-tools-libs
      - kernel-tools-libs-devel
  become: true
  notify: reboot

- name: Install kernel tools/extras required for compiling kernel modules - for RedHat == 7.
  ansible.builtin.package:
    state: latest
    update_cache: true
    name:
      - kernel-abi-whitelists
  when:
    - ansible_facts['os_family'] == "RedHat"
    - ansible_facts['distribution_major_version'] == "7"
  become: true
  notify: reboot

- name: Install kernel tools/extras required for compiling kernel modules - for RedHat >= 8.
  ansible.builtin.package:
    state: latest
    update_cache: true
    name:
      - kernel-abi-stablelists
  when:
    - ansible_facts['os_family'] == "RedHat"
    - ansible_facts['distribution_major_version'] >= "8"
  become: true
  notify: reboot

- name: Flush handlers
  ansible.builtin.meta: flush_handlers

- name: Install the Lustre client - for RedHat <= 8.
  ansible.builtin.package:
    state: latest
    update_cache: true
    name:
      - lustre-client-dkms
      - lustre-client
  when:
    - ansible_facts['os_family'] == "RedHat"
    - ansible_facts['distribution_major_version'] <= "8"
  become: true

#
# Temporary workaround required for el9, because the latest lustre-client-dkms-2.15.3-1.el9.noarch
# has a dependency on /usr/bin/python2, which is not available for el9.
# This bug has been fixed in the Lustre repo, but new RPMs are not available yet...
#
# Note we cannot use ansible.builtin.package with "skip_broken: true",
# because that feature is broken in Ansible < 2.14 and does nothing.
#
- name: Install the Lustre client - for RedHat >= 9 work around part 1.
  ansible.builtin.package:
    state: latest
    update_cache: true
    skip_broken: true
    name:
      - lustre-client
  when:
    - ansible_facts['os_family'] == "RedHat"
    - ansible_facts['distribution_major_version'] >= "9"
  become: true

- name: Install the Lustre client - for RedHat >= 9 work around part 2.
  ansible.builtin.command:
    cmd: dnf install lustre-client-dkms --skip-broken
  when:
    - ansible_facts['os_family'] == "RedHat"
    - ansible_facts['distribution_major_version'] >= "9"
  become: true

- name: Load the Lustre kernel modules.
  community.general.modprobe:
    name: "{{ item }}"
    state: present
  with_items:
    - lnet
    - lustre
  become: true

- name: Remove old style /etc/modprobe.d/lustre.conf.
  ansible.builtin.file:
    path: /etc/modprobe.d/lustre.conf
    state: absent
  become: true

- name: 'Create lustre lnet config: part 1.'
  ansible.builtin.command:
    cmd: |
         lnetctl lnet configure
  changed_when: true
  become: true

- name: 'Create lustre lnet config: part 2.'
  ansible.builtin.command:
    cmd: |
         lnetctl net del --net tcp
  register: lnetctl_del_status
  changed_when:
    - lnetctl_del_status.rc == 0
  failed_when:
    - lnetctl_del_status.rc > 0
    - '"errno: -2" not in lnetctl_del_status.stderr'
  become: true

- name: 'Create lustre lnet config: part 3.'
  ansible.builtin.command:
    cmd: |
         lnetctl net add --net "{{ item.name }}" --if "{{ item.interface }}"
  register: lnetctl_add_status
  changed_when:
    - lnetctl_add_status.rc == 0
  failed_when:
    - lnetctl_add_status.rc > 0
    - '"errno: -17" not in lnetctl_add_status.stderr'
  with_items: "{{ lustre_client_networks }}"
  become: true

- name: Save lustre lnet config to /etc/lnet.conf
  ansible.builtin.shell:
    cmd: |
         checksum_old=$(md5sum /etc/lnet.conf)
         lnetctl export -b /etc/lnet.conf
         checksum_new=$(md5sum /etc/lnet.conf)
         if [[ "${checksum_old}" != "${checksum_new}" ]]; then
             echo 'lnet.conf has changed.'
         fi
  register: lnetconf_status
  changed_when:
    - '"lnet.conf has changed." in lnetconf_status.stdout'
  notify:
    - restart_lnet
  become: true

- name: Patch lnet.service file for systemd to ignore failure if a Lustre network ID was already loaded.
  ansible.builtin.lineinfile:
    path: /usr/lib/systemd/system/lnet.service
    backup: true
    insertafter: '\[Service\]'
    regexp: '^#?SuccessExitStatus='
    line: 'SuccessExitStatus=239'  # lustre NID already loaded.
    owner: root
    group: root
    mode: '0644'
  notify:
    - restart_lnet
  become: true

- name: Patch lnet.service file for systemd to start lnet.service before remote-fs.target.
  ansible.builtin.lineinfile:
    path: /usr/lib/systemd/system/lnet.service
    backup: true
    insertafter: '\[Install\]'
    regexp: '^#?WantedBy='
    line: 'WantedBy=multi-user.target remote-fs-pre.target'
    owner: root
    group: root
    mode: '0644'
  notify:
    - reenable_lnet
    - restart_lnet
  become: true

- name: Start lnet.service.
  ansible.builtin.systemd:
    name: lnet.service
    enabled: true
    state: started
    daemon_reload: true
  become: true
...
