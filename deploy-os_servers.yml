#
# See README.md for instructins how to use this playbook.
#
---
- name: 'Sanity checks before we start.'
  hosts: localhost
  connection: local
  pre_tasks:
    - name: 'Verify Ansible version meets requirements.'
      ansible.builtin.assert:
        that: "ansible_version.full is version_compare('2.10', '>=')"
        msg: 'You must update Ansible to at least 2.10.x to use this playbook.'
##############################################################################
# Create vxlans, router, security groups and other components we need
# before we can create Virtual Machines.
##############################################################################
- name: Create components required for creating VMs using OpenStack API.
  hosts: localhost
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which would fail to use the interpretor from an activated virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: "Create {{ network_private_management_id }} network."
      openstack.cloud.network:
        state: present
        name: "{{ network_private_management_id }}"
        external: false
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Assign subnet to {{ network_private_management_id }} network."
      openstack.cloud.subnet:
        # 'name' must be the same as 'network_name' or else creating routers for this subnet will fail due to known bug.
        name: "{{ network_private_management_id }}"
        network_name: "{{ network_private_management_id }}"
        state: present
        cidr: "{{ network_private_management_cidr }}"
        # Bug: https://storyboard.openstack.org/#!/story/2008172
        # openstack.cloud.subnet is not idempotent and will fail when a router is present
        # and which is linked to the gateway_ip of the subnet.
        # In that case you must delete the router in order to be able to run this playbook,
        # which may require disassociating floating IPs first: yikes!
        gateway_ip: "{{ network_private_management_gw }}"
        enable_dhcp: true
        dns_nameservers: "{{ nameservers }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Create {{ network_private_storage_id }} network."
      openstack.cloud.network:
        name: "{{ network_private_storage_id }}"
        state: present
        external: false
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Assign subnet to {{ network_private_storage_id }} network."
      openstack.cloud.subnet:
        # 'name' must be the same as 'network_name' or else creating routers for this subnet will fail due to known bug.
        name: "{{ network_private_storage_id }}"
        network_name: "{{ network_private_storage_id }}"
        state: present
        cidr: "{{ network_private_storage_cidr }}"
        no_gateway_ip: true
        enable_dhcp: true
        dns_nameservers: "{{ nameservers }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Create router to bridge {{ network_public_external_id }} and {{ network_private_management_id }} networks."
      openstack.cloud.router:
        state: present
        name: "Router bridging {{ network_public_external_id }} and {{ network_private_management_id }}"
        network: "{{ network_public_external_id }}"
        interfaces:
          - "{{ network_private_management_id }}"
          #
          # Specifying only the network_private_management_id will fail when the default gateway IP
          # from that subnet is already in use. In that case we must specify an IP,
          # but there is no easy, safe way to determine which one we should use....
          #
          # - net: "{{ network_private_management_id }}"
          #   subnet: "{{ network_private_management_id }}"
          #   portip: 10.10.1.1
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: false
    #
    # Jumphosts security group.
    #
    - name: "Create security group for {{ stack_prefix }} jumphosts."
      openstack.cloud.security_group:
        state: present
        name: "{{ stack_prefix }}_jumphosts"
        description: |
                     Security group for security hardened jumphosts bridging the external and internal network.
                     Allows SSH inbound on both port 22 and 443.
                     Allows ICMP inbound.
                     Allows all outbound traffic.
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Add rules to {{ stack_prefix }}_jumphosts security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_jumphosts"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port }}"
        port_range_max: "{{ item.port }}"
        remote_ip_prefix: 0.0.0.0/0
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port: 22  # SSH
        - protocol: tcp
          port: 443  # SSH fallback
        - protocol: tcp
          port: 636  # LDAPS
        - protocol: icmp
          port: -1  # ICMP protocol does not have any ports.
    #
    # Data staging security group.
    #
    - name: "Create security group for {{ stack_prefix }} data staging servers."
      openstack.cloud.security_group:
        state: present
        name: "{{ stack_prefix }}_ds"
        description: |
                     Security group for data staging severs without access to the internal network.
                     Allows SSH inbound on both port 22 and 443.
                     Allows ICMP inbound.
                     Allows all outbound traffic.
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Add rules to {{ stack_prefix }}_ds security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_ds"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port }}"
        port_range_max: "{{ item.port }}"
        remote_ip_prefix: 0.0.0.0/0
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port: 22  # SSH
        - protocol: tcp
          port: 443  # SSH fallback
        - protocol: tcp
          port: 636  # LDAPS; ToDo: restrict to {{ ldap_uri }}
        - protocol: icmp
          port: -1  # ICMP protocol does not have any ports.
    #
    # Cluster security groups.
    #
    - name: "Create management network security group for {{ stack_prefix }} cluster machines behind jumphost."
      openstack.cloud.security_group:
        state: present
        name: "{{ stack_prefix }}_cluster"
        description: |
                     Management security group for cluster machines behind a jumphost.
                     Allows SSH and ICMP inbound from machines in the jumphost security group.
                     Allows any traffic inbound from other machines in the same security group.
                     Allows all outbound traffic.
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Add rule to {{ stack_prefix }}_cluster security group: allow LDAPS inbound on port 636."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_cluster"
        direction: ingress
        protocol: tcp
        port_range_min: 636
        port_range_max: 636
        remote_ip_prefix: 0.0.0.0/0  # ToDo: restrict to {{ ldap_uri }}
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Add rules to {{ stack_prefix }}_cluster security group: allow inbound traffic from {{ stack_prefix }}_jumphosts security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_cluster"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port }}"
        port_range_max: "{{ item.port }}"
        remote_group: "{{ stack_prefix }}_jumphosts"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port: 22  # SSH
        - protocol: icmp
          port: -1  # ICMP protocol does not have any ports.
    - name: "Add rules to {{ stack_prefix }}_cluster security group: allow inbound traffic from machines in the same security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_cluster"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port }}"
        port_range_max: "{{ item.port }}"
        remote_group: "{{ stack_prefix }}_cluster"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port: -1  # Port range min -1 & max -1 means the same as min 1 & max 65535, but the latter is not idempotent due to a known bug.
        - protocol: udp
          port: -1  # Port range min -1 & max -1 means the same as min 1 & max 65535, but the latter is not idempotent due to a known bug.
        - protocol: icmp
          port: -1  # ICMP protocol does not have any ports.
    - name: "Create storage network security group for {{ stack_prefix }} cluster machines."
      openstack.cloud.security_group:
        state: present
        name: "{{ stack_prefix }}_storage"
        description: |
                     Storage security group for cluster machines.
                     Allows any traffic from storage servers.
                     Allows any traffic inbound from other machines in the same security group.
                     Allows all outbound traffic.
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Add rule to {{ stack_prefix }}_storage security group: allow inbound traffic from storage servers."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_storage"
        direction: ingress
        protocol: "{{ item.1 }}"
        port_range_min: -1  # For TCP and UDP port range min -1 & max -1 means the same as min 1 & max 65535, but the latter is not idempotent due to a known bug.
        port_range_max: -1  # ICMP protocol does not have any ports.
        remote_ip_prefix: "{{ item.0 }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      loop: "{{ network_private_storage_allow_ingress | product(['tcp', 'udp', 'icmp']) | list }}"
      when: network_private_storage_allow_ingress is defined and network_private_storage_allow_ingress | length >= 1
    - name: "Add rules to {{ stack_prefix }}_storage security group: allow inbound traffic from machines in the same security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_storage"
        direction: ingress
        protocol: "{{ item }}"
        port_range_min: -1  # For TCP and UDP port range min -1 & max -1 means the same as min 1 & max 65535, but the latter is not idempotent due to a known bug.
        port_range_max: -1  # ICMP protocol does not have any ports.
        remote_group: "{{ stack_prefix }}_storage"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - tcp
        - udp
        - icmp
    #
    # Configure IRODS security group using Openstack API.
    #
    - name: "Create security group for {{ stack_prefix }} IRODs machines."
      openstack.cloud.security_group:
        state: present
        name: "{{ stack_prefix }}_irods"
        description: |
                     Security group for iRODS machines.
                     Allows SSH and ICMP inbound from jumphosts.
                     Allows DAVRODS on port 443.
                     Allows iRODS inbound on ports 1247 and 20000-20199.
                     Allows all outbound traffic.
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: groups['irods'] | default([]) | length >= 1
    - name: "Add rules to {{ stack_prefix }}_irods security group: allow inbound traffic from {{ stack_prefix }}_jumphosts security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_irods"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port_min }}"
        port_range_max: "{{ item.port_max }}"
        remote_group: "{{ stack_prefix }}_jumphosts"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port_min: 22  # SSH
          port_max: 22  # SSH
        - protocol: icmp
          port_min: -1  # ICMP protocol does not have any ports.
          port_max: -1  # ICMP protocol does not have any ports.
      when: groups['irods'] | default([]) | length >= 1
    - name: "Add rules to {{ stack_prefix }}_irods security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_irods"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port_min }}"
        port_range_max: "{{ item.port_max }}"
        remote_ip_prefix: 0.0.0.0/0
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port_min: 443  # DAVRODS
          port_max: 443  # DAVRODS
        - protocol: tcp
          port_min: 636  # LDAPS
          port_max: 636  # LDAPS
        - protocol: tcp
          port_min: 1247  # iRODS
          port_max: 1247  # iRODS
        - protocol: tcp
          port_min: 5432  # iRODS
          port_max: 5432  # iRODS
        - protocol: tcp
          port_min: 20000  # iRODS
          port_max: 20199  # iRODS
      when: groups['irods'] | default([]) | length >= 1
    - name: "Add rules to {{ stack_prefix }}_irods security group: allow inbound traffic from machines in the same security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_irods"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port }}"
        port_range_max: "{{ item.port }}"
        remote_group: "{{ stack_prefix }}_irods"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port: -1  # Port range min -1 & max -1 means the same as min 1 & max 65535, but the latter is not idempotent due to a known bug.
        - protocol: udp
          port: -1  # Port range min -1 & max -1 means the same as min 1 & max 65535, but the latter is not idempotent due to a known bug.
        - protocol: icmp
          port: -1  # ICMP protocol does not have any ports.
      when: groups['irods'] | default([]) | length >= 1
    #
    # (Pulp) repo server security group.
    #
    # Note: only local admin accounts on repo machines, so no need for LDAPS traffic on port 636.
    #
    - name: "Create security group for {{ stack_prefix }} repo machines behind jumphost."
      openstack.cloud.security_group:
        state: present
        name: "{{ stack_prefix }}_repo"
        description: |
                     Security group for repo machines behind a jumphost.
                     Allows SSH and ICMP inbound from machines in the jumphost security group.
                     Allows HTTPS traffic inbound from machines in cluster and irods security group.
                     Allows all outbound traffic.
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: "Add rules to {{ stack_prefix }}_repo security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_repo"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port }}"
        port_range_max: "{{ item.port }}"
        remote_group: "{{ item.remote_group }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port: 22  # SSH
          remote_group: "{{ stack_prefix }}_jumphosts"
        - protocol: icmp
          port: -1  # ICMP protocol does not have any ports.
          remote_group: "{{ stack_prefix }}_jumphosts"
        - protocol: tcp
          port: 443  # HTTPS
          remote_group: "{{ stack_prefix }}_cluster"
        - protocol: icmp
          port: -1  # ICMP protocol does not have any ports.
          remote_group: "{{ stack_prefix }}_cluster"
    - name: "Add rules to {{ stack_prefix }}_repo security group: allow inbound traffic from {{ stack_prefix }}_irods security group."
      openstack.cloud.security_group_rule:
        security_group: "{{ stack_prefix }}_repo"
        direction: ingress
        protocol: "{{ item.protocol }}"
        port_range_min: "{{ item.port }}"
        port_range_max: "{{ item.port }}"
        remote_group: "{{ item.remote_group }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      with_items:
        - protocol: tcp
          port: 443  # HTTPS
          remote_group: "{{ stack_prefix }}_irods"
        - protocol: icmp
          port: -1  # ICMP protocol does not have any ports.
          remote_group: "{{ stack_prefix }}_irods"
      when: groups['irods'] | default([]) | length >= 1
##############################################################################
# Create network ports for all machines from inventory using Openstack API.
##############################################################################
- name: "Create network port for machines with {{ network_private_management_id }} network interface in {{ stack_prefix }}_jumphosts security group."
  hosts:
    - jumphost
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: "Use pre-defined address from group_vars/{{ stack_name }}/ip_addresses.yml."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_jumphosts"
        fixed_ips:
          - ip_address: "{{ ip_addresses[inventory_hostname][network_private_management_id]['address'] }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is defined
    - name: "Use new random address from defined subnet."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_jumphosts"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is not defined
- name: "Create network port for machines with {{ network_private_management_id }} network interface in {{ stack_prefix }}_ds security group."
  hosts:
    - data_transfer
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: "Use pre-defined address from group_vars/{{ stack_name }}/ip_addresses.yml."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_ds"
        fixed_ips:
          - ip_address: "{{ ip_addresses[inventory_hostname][network_private_management_id]['address'] }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is defined
    - name: "Use new random address from defined subnet."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_ds"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is not defined
- name: "Create network port for machines with {{ network_private_management_id }} network interface in {{ stack_prefix }}_repo security group."
  hosts:
    - repo
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: "Use pre-defined address from group_vars/{{ stack_name }}/ip_addresses.yml."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_repo"
        fixed_ips:
          - ip_address: "{{ ip_addresses[inventory_hostname][network_private_management_id]['address'] }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is defined
    - name: "Use new random address from defined subnet."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_repo"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is not defined
- name: "Create network port for machines with {{ network_private_management_id }} network interface in {{ stack_prefix }}_irods security group."
  hosts:
    - irods
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: "Use pre-defined address from group_vars/{{ stack_name }}/ip_addresses.yml."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_irods"
        fixed_ips:
          - ip_address: "{{ ip_addresses[inventory_hostname][network_private_management_id]['address'] }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is defined
    - name: "Use new random address from defined subnet."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_irods"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is not defined
- name: "Create network port for machines with {{ network_private_management_id }} network interface in {{ stack_prefix }}_cluster security group."
  hosts:
    - administration
    - compute_vm
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: "Use pre-defined address from group_vars/{{ stack_name }}/ip_addresses.yml."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_cluster"
        fixed_ips:
          - ip_address: "{{ ip_addresses[inventory_hostname][network_private_management_id]['address'] }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is defined
    - name: "Use new random address from defined subnet."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        network: "{{ network_private_management_id }}"
        security_groups: "{{ stack_prefix }}_cluster"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id]['address'] is not defined
- name: "Create network ports for machines with {{ network_private_storage_id }} network interface in {{ stack_prefix }}_cluster security group."
  hosts:
    - administration
    - compute_vm
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: "Use pre-defined address from group_vars/{{ stack_name }}/ip_addresses.yml."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_storage_id }}"
        network: "{{ network_private_storage_id }}"
        security_groups: "{{ stack_prefix }}_storage"
        fixed_ips:
          - ip_address: "{{ ip_addresses[inventory_hostname][network_private_storage_id]['address'] }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_storage_id]['address'] is defined
    - name: "Use new random address from defined subnet."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_storage_id }}"
        network: "{{ network_private_storage_id }}"
        security_groups: "{{ stack_prefix }}_storage"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_storage_id]['address'] is not defined
- name: "Create network ports for machines with {{ network_private_management_id_13 }} network interface in {{ stack_prefix }}_irods security group."
  hosts:
    - irods
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: "Use pre-defined address from group_vars/{{ stack_name }}/ip_addresses.yml."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id_13 }}"
        network: "{{ network_private_management_id_13 }}"
        security_groups: "{{ stack_prefix }}_irods"
        fixed_ips:
          - ip_address: "{{ ip_addresses[inventory_hostname][network_private_management_id_13]['address'] }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id_13]['address'] is defined
    - name: "Use new random address from defined subnet."
      openstack.cloud.port:
        state: present
        name: "{{ inventory_hostname }}-{{ network_private_management_id_13 }}"
        network: "{{ network_private_management_id_13 }}"
        security_groups: "{{ stack_prefix }}_irods"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      when: ip_addresses[inventory_hostname][network_private_management_id_13]['address'] is not defined
##############################################################################
# Configure jumphosts from inventory using Openstack API.
##############################################################################
- name: Create jumphosts.
  hosts: jumphost
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: Create jumphost server.
      openstack.cloud.server:
        state: present
        name: "{{ inventory_hostname }}"
        image: "{{ cloud_image }}"
        flavor: "{{ cloud_flavor }}"
        security_groups: "{{ stack_prefix }}_jumphosts"
        auto_floating_ip: false
        nics:
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        userdata: |
          #cloud-config
          password: "{{ cloud_console_pass }}"
          chpasswd: { expire: False }
          #
          # Add each entry to ~/.ssh/authorized_keys for the configured user
          # or the first user defined in the user definition directive.
          #
          ssh_authorized_keys:
          {% for public_key in public_keys_of_local_admins %}  - {{ public_key }}
          {% endfor %}
        availability_zone: "{{ availability_zone }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      register: jumphost_vm
    - name: Assign floating IP to jumphost
      openstack.cloud.floating_ip:
        server: "{{ inventory_hostname }}"
        state: present
        reuse: true
        network: "{{ network_public_external_id }}"
        nat_destination: "{{ network_private_management_id }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      #
      # Known bug https://github.com/ansible/ansible/issues/57451
      # openstack.cloud.floating_ip is not idempotent:
      # Succeeds only the first time and throws error on any subsequent calls.
      # Therefore we use a "when" with a silly complex jinja filter including a JMESpath query
      # to check if the VM already has a floating IP linked to an interface in the correct VXLAN.
      #
      when: (jumphost_vm.server.addresses | dict2items(key_name='vlan', value_name='specs') | json_query(query)) != network_private_management_id
      vars:
        query: '[?specs[?"OS-EXT-IPS:type"==`floating`]].vlan | [0]'
    - name: Make sure jumphosts are started.
      openstack.cloud.server_action:
        action: start
        server: "{{ inventory_hostname }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
##############################################################################
# Configure data staging servers from inventory using Openstack API.
##############################################################################
- name: Create data staging servers.
  hosts: data_transfer
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: Create persistent data volume for data staging servers.
      openstack.cloud.volume:
        display_name: "{{ inventory_hostname }}-volume"
        size: "{{ local_volume_size_extra }}"
        state: present
        availability_zone: "{{ storage_availability_zone | default('nova') }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Create data staging servers.
      openstack.cloud.server:
        state: present
        name: "{{ inventory_hostname }}"
        image: "{{ cloud_image }}"
        volume_size: "{{ local_volume_size_root }}"
        terminate_volume: true
        boot_from_volume: true
        flavor: "{{ cloud_flavor }}"
        security_groups: "{{ stack_prefix }}_ds"
        auto_floating_ip: false
        nics:
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        userdata: |
          #cloud-config
          password: "{{ cloud_console_pass }}"
          chpasswd: { expire: False }
          #
          # Add each entry to ~/.ssh/authorized_keys for the configured user
          # or the first user defined in the user definition directive.
          #
          ssh_authorized_keys:
          {% for public_key in public_keys_of_local_admins %}  - {{ public_key }}
          {% endfor %}
        availability_zone: "{{ availability_zone }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      register: ds_vm
    - name: Assign floating IPs to data staging servers.
      openstack.cloud.floating_ip:
        server: "{{ inventory_hostname }}"
        state: present
        reuse: true
        network: "{{ network_public_external_id }}"
        nat_destination: "{{ network_private_management_id }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      #
      # Known bug https://github.com/ansible/ansible/issues/57451
      # openstack.cloud.floating_ip is not idempotent:
      # Succeeds only the first time and throws error on any subsequent calls.
      # Therefore we use a "when" with a silly complex jinja filter including a JMESpath query
      # to check if the VM already has a floating IP linked to an interface in the correct VXLAN.
      #
      when: (ds_vm.server.addresses | dict2items(key_name='vlan', value_name='specs') | json_query(query)) != network_private_management_id
      vars:
        query: '[?specs[?"OS-EXT-IPS:type"==`floating`]].vlan | [0]'
    - name: Attach local storage volume to data staging servers.
      openstack.cloud.server_volume:
        server: "{{ inventory_hostname }}"
        volume: "{{ inventory_hostname }}-volume"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Make sure data staging servers are started.
      openstack.cloud.server_action:
        action: start
        server: "{{ inventory_hostname }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
##############################################################################
# Configure repo servers from inventory using Openstack API.
##############################################################################
- name: Create repo servers.
  hosts: repo
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: Create repo server.
      openstack.cloud.server:
        state: present
        name: "{{ inventory_hostname }}"
        image: "{{ cloud_image }}"
        volume_size: "{{ local_volume_size_root }}"
        terminate_volume: true
        boot_from_volume: true
        flavor: "{{ cloud_flavor }}"
        security_groups: "{{ stack_prefix }}_repo"
        auto_floating_ip: false
        nics:
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
        userdata: |
          #cloud-config
          password: "{{ cloud_console_pass }}"
          chpasswd: { expire: False }
          #
          # Add each entry to ~/.ssh/authorized_keys for the configured user
          # or the first user defined in the user definition directive.
          #
          ssh_authorized_keys:
          {% for public_key in public_keys_of_local_admins %}  - {{ public_key }}
          {% endfor %}
        availability_zone: "{{ availability_zone }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Make sure repo servers are started.
      openstack.cloud.server_action:
        action: start
        server: "{{ inventory_hostname }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
##############################################################################
# Configure IRODS servers from inventory using Openstack API.
##############################################################################
- name: Create IRODS catalogus servers.
  hosts: irods
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: Create persistent data volume for irods server.
      openstack.cloud.volume:
        display_name: "{{ inventory_hostname }}-volume"
        size: "{{ local_volume_size_extra }}"
        state: present
        availability_zone: "{{ storage_availability_zone | default('nova') }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Create irods server.
      openstack.cloud.server:
        state: present
        name: "{{ inventory_hostname }}"
        image: "{{ cloud_image }}"
        flavor: "{{ cloud_flavor }}"
        security_groups: "{{ stack_prefix }}_irods"
        auto_floating_ip: false
        nics:
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id_13 }}"
        userdata: |
          #cloud-config
          password: "{{ cloud_console_pass }}"
          chpasswd: { expire: False }
          #
          # Add each entry to ~/.ssh/authorized_keys for the configured user
          # or the first user defined in the user definition directive.
          #
          ssh_authorized_keys:
          {% for public_key in public_keys_of_local_admins %}  - {{ public_key }}
          {% endfor %}
        availability_zone: "{{ availability_zone }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
      register: irods_vm
    - name: Make sure irods nodes are started.
      openstack.cloud.server_action:
        action: start
        server: "{{ inventory_hostname }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
##############################################################################
# Configure UIs from inventory using Openstack API.
##############################################################################
- name: Create User Interfaces.
  hosts: user_interface
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: Create UI server.
      openstack.cloud.server:
        state: present
        name: "{{ inventory_hostname }}"
        image: "{{ cloud_image }}"
        volume_size: "{{ local_volume_size_root }}"
        terminate_volume: true
        boot_from_volume: true
        flavor: "{{ cloud_flavor }}"
        security_groups:
          - "{{ stack_prefix }}_cluster"
          - "{{ stack_prefix }}_storage"
        auto_floating_ip: false
        nics:
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
          - port-name: "{{ inventory_hostname }}-{{ network_private_storage_id }}"
        userdata: |
          #cloud-config
          password: "{{ cloud_console_pass }}"
          chpasswd: { expire: False }
          #
          # Add each entry to ~/.ssh/authorized_keys for the configured user
          # or the first user defined in the user definition directive.
          #
          ssh_authorized_keys:
          {% for public_key in public_keys_of_local_admins %}  - {{ public_key }}
          {% endfor %}
        availability_zone: "{{ availability_zone }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Make sure UIs are started.
      openstack.cloud.server_action:
        action: start
        server: "{{ inventory_hostname }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
##############################################################################
# Configure compute nodes from inventory using Openstack API.
##############################################################################
- name: Create compute nodes.
  hosts:
    - compute_vm
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: Create persistent data volume for compute node.
      openstack.cloud.volume:
        display_name: "{{ inventory_hostname }}-volume"
        size: "{{ local_volume_size_extra }}"
        state: present
        availability_zone: "{{ storage_availability_zone | default('nova') }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Create compute node server.
      openstack.cloud.server:
        state: present
        name: "{{ inventory_hostname }}"
        image: "{{ cloud_image }}"
        volume_size: "{{ local_volume_size_root }}"
        terminate_volume: true
        boot_from_volume: true
        flavor: "{{ cloud_flavor }}"
        security_groups:
          - "{{ stack_prefix }}_cluster"
          - "{{ stack_prefix }}_storage"
        auto_floating_ip: false
        nics:
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
          - port-name: "{{ inventory_hostname }}-{{ network_private_storage_id }}"
        userdata: |
          #cloud-config
          password: "{{ cloud_console_pass }}"
          chpasswd: { expire: False }
          #
          # Add each entry to ~/.ssh/authorized_keys for the configured user
          # or the first user defined in the user definition directive.
          #
          ssh_authorized_keys:
          {% for public_key in public_keys_of_local_admins %}  - {{ public_key }}
          {% endfor %}
        availability_zone: "{{ availability_zone }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Attach local storage volume to compute node.
      openstack.cloud.server_volume:
        server: "{{ inventory_hostname }}"
        volume: "{{ inventory_hostname }}-volume"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Make sure compute nodes are started.
      openstack.cloud.server_action:
        action: start
        server: "{{ inventory_hostname }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
#############################################################################
# Configure SAI from inventory using Openstack API.
#############################################################################
- name: Create and Deploy SAI.
  hosts:
    - sys_admin_interface
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: Create persistent data volume for SAI.
      openstack.cloud.volume:
        display_name: "{{ inventory_hostname }}-volume"
        size: "{{ local_volume_size_extra }}"
        state: present
        availability_zone: "{{ storage_availability_zone | default('nova') }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Create SAI server.
      openstack.cloud.server:
        state: present
        name: "{{ inventory_hostname }}"
        image: "{{ cloud_image }}"
        volume_size: "{{ local_volume_size_root }}"
        terminate_volume: true
        boot_from_volume: true
        flavor: "{{ cloud_flavor }}"
        security_groups:
          - "{{ stack_prefix }}_cluster"
          - "{{ stack_prefix }}_storage"
        auto_floating_ip: false
        nics:
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
          - port-name: "{{ inventory_hostname }}-{{ network_private_storage_id }}"
        userdata: |
          #cloud-config
          password: "{{ cloud_console_pass }}"
          chpasswd: { expire: False }
          #
          # Add each entry to ~/.ssh/authorized_keys for the configured user
          # or the first user defined in the user definition directive.
          #
          ssh_authorized_keys:
          {% for public_key in public_keys_of_local_admins %}  - {{ public_key }}
          {% endfor %}
        availability_zone: "{{ availability_zone }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Attach local storage volume to SAI server.
      openstack.cloud.server_volume:
        server: "{{ inventory_hostname }}"
        volume: "{{ inventory_hostname }}-volume"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
#############################################################################
# Configure DAI from inventory using Openstack API.
#############################################################################
- name: Create and Deploy DAI.
  hosts:
    - deploy_admin_interface
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which fails to use the interpretor from an activated virtual environment
    # and hence fails to find the OpenStackSDK if it was installed in a virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    - name: Create persistent data volume for DAI.
      openstack.cloud.volume:
        display_name: "{{ inventory_hostname }}-volume"
        size: "{{ local_volume_size_extra }}"
        state: present
        availability_zone: "{{ storage_availability_zone | default('nova') }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Create DAI server.
      openstack.cloud.server:
        state: present
        name: "{{ inventory_hostname }}"
        image: "{{ cloud_image }}"
        volume_size: "{{ local_volume_size_root }}"
        terminate_volume: true
        boot_from_volume: true
        flavor: "{{ cloud_flavor }}"
        security_groups:
          - "{{ stack_prefix }}_cluster"
          - "{{ stack_prefix }}_storage"
        auto_floating_ip: false
        nics:
          - port-name: "{{ inventory_hostname }}-{{ network_private_management_id }}"
          - port-name: "{{ inventory_hostname }}-{{ network_private_storage_id }}"
        userdata: |
          #cloud-config
          password: "{{ cloud_console_pass }}"
          chpasswd: { expire: False }
          #
          # Add each entry to ~/.ssh/authorized_keys for the configured user
          # or the first user defined in the user definition directive.
          #
          ssh_authorized_keys:
          {% for public_key in public_keys_of_local_admins %}  - {{ public_key }}
          {% endfor %}
        availability_zone: "{{ availability_zone }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Attach local storage volume to DAI server.
      openstack.cloud.server_volume:
        server: "{{ inventory_hostname }}"
        volume: "{{ inventory_hostname }}-volume"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
    - name: Make sure admin interface servers are started.
      openstack.cloud.server_action:
        action: start
        server: "{{ inventory_hostname }}"
        wait: true
        timeout: "{{ openstack_api_timeout }}"
##############################################################################
# Get IPs addresses from API for static hostname lookup with /etc/hosts.
##############################################################################
- name: Fetch network addresses assigned to VMs using OpenStack API.
  hosts: localhost
  connection: local
  gather_facts: false
  vars:
    #
    # Disable Ansible's interpretor detection logic,
    # which would fail to use the interpretor from an activated virtual environment.
    #
    - ansible_python_interpreter: python
  tasks:
    #
    # Note: we fetch info for all servers relevant or not
    # as filtering directly during the API call is problematic.
    # Will filter the results for the relevant servers later on.
    #
    - name: Get info on floating IPs from OpenStack API.
      openstack.cloud.floating_ip_info:
      register: api_fip_info
    - name: Get info on networks from OpenStack API.
      openstack.cloud.networks_info:
      register: api_network_info
    - name: Get server info from OpenStack API.
      openstack.cloud.server_info:
      register: api_server_info
    - name: "Add addresses to {{ playbook_dir }}/group_vars/{{ stack_name }}/ip_addresses.yml.new"
      ansible.builtin.template:
        src: "{{ playbook_dir }}/group_vars/template/ip_addresses.yml.j2"
        dest: "{{ playbook_dir }}/group_vars/{{ stack_name }}/ip_addresses.yml.new"
        mode: '0644'
      vars:
        relevant_servers_list: "{{ groups['jumphost'] | default([]) + \
                                   groups['data_transfer'] | default([]) + \
                                   groups['repo'] | default([]) + \
                                   groups['cluster'] | default([]) }}"
        relevant_servers_info: "{{ api_server_info.openstack_servers | selectattr('name', 'in', relevant_servers_list) | list }}"
    - name: "ToDo"
      ansible.builtin.debug:
        msg: |
             ***********************************************************************************************************
             IMPORTANT: Manual work!
                        Ansible created:
                            {{ playbook_dir }}/group_vars/{{ stack_name }}/ip_addresses.yml.new
                        Please inspect this file carefully with:
                            diff -y {{ playbook_dir }}/group_vars/{{ stack_name }}/ip_addresses.yml{.new,}
                        and if Ok execute:
                            mv {{ playbook_dir }}/group_vars/{{ stack_name }}/ip_addresses.yml{.new,}
             ***********************************************************************************************************
...
